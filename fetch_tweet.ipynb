{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tweepy\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate():\n",
    "  # keys and tokens from the Twitter Dev Console\n",
    "  consumer_key = '#'\n",
    "  consumer_secret = '#'\n",
    "  access_token = '#-#'\n",
    "  access_token_secret = '#'\n",
    "\n",
    "  BEARER_TOKEN = '#%#'\n",
    "  # attempt authentication\n",
    "  try:\n",
    "    print(\"Authenticating...\")\n",
    "    # create Client object\n",
    "    client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "    # set access token and secret\n",
    "    # create tweepy API object to fetch tweets\n",
    "    print(\"API value:....   \", client)\n",
    "    return client\n",
    "  except Exception as e:\n",
    "    print(\"Error: Authentication Failed\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating...\n",
      "API value:....    <tweepy.client.Client object at 0x7f8f90739910>\n"
     ]
    }
   ],
   "source": [
    "API = authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(query, start_time, end_time, next_token, geocode = '53.5500,2.4333,1mi', max_results=500,):\n",
    "  '''\n",
    "  Main function to fetch tweets.\n",
    "  '''\n",
    "  # empty list to store parsed tweets\n",
    "  tweets = []\n",
    "\n",
    "  expansions = ['author_id,in_reply_to_user_id,geo.place_id']\n",
    "  tweet_fields = ['id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source']\n",
    "  user_fields =  ['id,name,username,created_at,description,public_metrics,verified']\n",
    "  place_fields = ['full_name,id,country,country_code,geo,name,place_type']\n",
    "  try:\n",
    "    # call twitter api to fetch tweets\n",
    "    fetched_tweets = API.search_all_tweets(query,\n",
    "      end_time=end_time,\n",
    "      start_time=start_time,\n",
    "      expansions=expansions,\n",
    "      tweet_fields=tweet_fields,\n",
    "      place_fields=place_fields,\n",
    "      user_fields=user_fields,\n",
    "      max_results=max_results,\n",
    "      next_token=next_token\n",
    "    )\n",
    "  \n",
    "    return fetched_tweets\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"Error getting tweets\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '(Education system OR education in the UK OR students in the UK OR UK education) lang:en (-is:retweet) place_country:GB'\n",
    "max_result = 500\n",
    "start_time='2019-10-01T00:00:01Z'\n",
    "end_time='2022-07-30T00:00:01Z'\n",
    "\n",
    "\n",
    "result = get_tweets(query=query, start_time=start_time, end_time=end_time, next_token=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def append_to_csv(result_set, fileName):\n",
    "\n",
    "    #A counter variable\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    #Loop through each tweet\n",
    "    for tweet in result_set.data:\n",
    "        \n",
    "        # We will create a variable for each since some of the keys might not exist for some tweets\n",
    "        # So we will account for that\n",
    "\n",
    "        # 1. Author ID\n",
    "        author_id = tweet['author_id']\n",
    "\n",
    "        # 2. Time created\n",
    "        created_at = tweet['created_at']\n",
    "\n",
    "        # 3. Geolocation\n",
    "        if ('geo' in tweet):   \n",
    "            geo = tweet['geo']['place_id']\n",
    "        else:\n",
    "            geo = \" \"\n",
    "\n",
    "        # 4. Tweet ID\n",
    "        tweet_id = tweet['id']\n",
    "\n",
    "        # 5. Language\n",
    "        lang = tweet['lang']\n",
    "\n",
    "        # 6. Tweet metrics\n",
    "        retweet_count = tweet['public_metrics']['retweet_count']\n",
    "        reply_count = tweet['public_metrics']['reply_count']\n",
    "        like_count = tweet['public_metrics']['like_count']\n",
    "        quote_count = tweet['public_metrics']['quote_count']\n",
    "\n",
    "        # 7. source\n",
    "        source = tweet['source']\n",
    "\n",
    "        # 8. Tweet text\n",
    "        text = tweet['text']\n",
    "        \n",
    "        # Assemble all data in a list\n",
    "        res = [author_id, created_at, geo, tweet_id, lang, like_count, quote_count, reply_count, retweet_count, source, text]        \n",
    "        \n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1\n",
    "\n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Tweets added from this response: \", counter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file\n",
    "csvFile = open(\"./data.csv\", \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "csvWriter.writerow(['author id', 'created_at', 'geo', 'id','lang', 'like_count', 'quote_count', 'reply_count','retweet_count','source','tweet'])\n",
    "csvFile.close()\n",
    "\n",
    "\n",
    "\n",
    "count = 0 # Counting tweets per time period\n",
    "max_count = 100 # Max tweets per time period\n",
    "flag = True\n",
    "next_token = None\n",
    " # Total number of tweets we collected from the loop\n",
    "# Check if flag is true\n",
    "def run_fetch(flag=True, next_token=None, count=0, total_tweets=0 ):\n",
    "  if (flag is not True):\n",
    "    return\n",
    "  while flag:\n",
    "    print(\"-------------------\")\n",
    "    print(\"Token: \", next_token)\n",
    "    result = get_tweets(query=query, start_time=start_time, end_time=end_time, max_results=max_count, next_token=next_token)\n",
    "    result_count = result.meta['result_count']\n",
    "    if result_count is not None and result_count > 0:\n",
    "      # print(\"Start Date: \", start_list[i])\n",
    "      append_to_csv(result, \"data.csv\")\n",
    "      count += result_count\n",
    "      total_tweets += result_count\n",
    "      print(\"Total # of Tweets added: \", total_tweets)\n",
    "      print(\"-------------------\")\n",
    "      if result.meta['next_token']:\n",
    "        # Save the token to use for next call\n",
    "        next_token = result.meta['next_token']\n",
    "        print(\"Next Token: \", next_token)\n",
    "        time.sleep(5)\n",
    "        run_fetch(True, next_token=next_token, count=count, total_tweets=total_tweets)\n",
    "      else:\n",
    "        # Since this is the final request, turn flag to false to move to the next time period.\n",
    "        flag = False\n",
    "        next_token = None\n",
    "    time.sleep(5)\n",
    "  print(\"Total number of results: \", total_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fetch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d3878fddc9c46165445784a10b090b010bb1a0b9835785e50e8f56ead986c33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
