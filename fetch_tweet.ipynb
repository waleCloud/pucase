{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tweepy\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate():\n",
    "  # keys and tokens from the Twitter Dev Console\n",
    "  consumer_key = '#'\n",
    "  consumer_secret = '#'\n",
    "  access_token = '#'\n",
    "  access_token_secret = '#'\n",
    "\n",
    "  BEARER_TOKEN = '#'\n",
    "  # attempt authentication\n",
    "  try:\n",
    "    print(\"Authenticating...\")\n",
    "    # create Client object\n",
    "    client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "    # set access token and secret\n",
    "    # create tweepy API object to fetch tweets\n",
    "    print(\"API value:....   \", client)\n",
    "    return client\n",
    "  except Exception as e:\n",
    "    print(\"Error: Authentication Failed\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating...\n",
      "API value:....    <tweepy.client.Client object at 0x7f9449f1ffa0>\n"
     ]
    }
   ],
   "source": [
    "API = authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(query, start_time, end_time, next_token, geocode = '53.5500,2.4333,1mi', max_results=500,):\n",
    "  '''\n",
    "  Main function to fetch tweets.\n",
    "  '''\n",
    "  # empty list to store parsed tweets\n",
    "  tweets = []\n",
    "\n",
    "  expansions = ['author_id,in_reply_to_user_id,geo.place_id']\n",
    "  tweet_fields = ['id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source']\n",
    "  user_fields =  ['id,name,username,created_at,description,public_metrics,verified']\n",
    "  place_fields = ['full_name,id,country,country_code,geo,name,place_type']\n",
    "  try:\n",
    "    # call twitter api to fetch tweets\n",
    "    fetched_tweets = API.search_all_tweets(query,\n",
    "      end_time=end_time,\n",
    "      start_time=start_time,\n",
    "      expansions=expansions,\n",
    "      tweet_fields=tweet_fields,\n",
    "      place_fields=place_fields,\n",
    "      user_fields=user_fields,\n",
    "      max_results=max_results,\n",
    "      next_token=next_token\n",
    "    )\n",
    "    print(len(fetched_tweets.data))\n",
    "    print(fetched_tweets.meta)\n",
    "  \n",
    "    return fetched_tweets\n",
    "\n",
    "  except Exception as e:\n",
    "    # print error (if any)\n",
    "    print(\"Error getting tweets\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476\n",
      "{'newest_id': '1487575860672491522', 'oldest_id': '1487455796677992451', 'result_count': 476, 'next_token': 'b26v89c19zqg8o3fpe4829txzerpzsg573dqdzz6fjmv1'}\n"
     ]
    }
   ],
   "source": [
    "query = 'International Students OR Schooling in the UK  -is:retweet place_country:GB'\n",
    "max_result = 500\n",
    "end_time='2022-01-30T00:00:01Z'\n",
    "start_time='2022-01-01T00:00:01Z',\n",
    "\n",
    "result = get_tweets(query=query, start_time=start_time, end_time=end_time, next_token=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def append_to_csv(result_set, fileName):\n",
    "\n",
    "    #A counter variable\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "\n",
    "    #Loop through each tweet\n",
    "    for tweet in result_set.data:\n",
    "        \n",
    "        # We will create a variable for each since some of the keys might not exist for some tweets\n",
    "        # So we will account for that\n",
    "\n",
    "        # 1. Author ID\n",
    "        author_id = tweet['author_id']\n",
    "\n",
    "        # 2. Time created\n",
    "        created_at = tweet['created_at']\n",
    "\n",
    "        # 3. Geolocation\n",
    "        if ('geo' in tweet):   \n",
    "            geo = tweet['geo']['place_id']\n",
    "        else:\n",
    "            geo = \" \"\n",
    "\n",
    "        # 4. Tweet ID\n",
    "        tweet_id = tweet['id']\n",
    "\n",
    "        # 5. Language\n",
    "        lang = tweet['lang']\n",
    "\n",
    "        # 6. Tweet metrics\n",
    "        retweet_count = tweet['public_metrics']['retweet_count']\n",
    "        reply_count = tweet['public_metrics']['reply_count']\n",
    "        like_count = tweet['public_metrics']['like_count']\n",
    "        quote_count = tweet['public_metrics']['quote_count']\n",
    "\n",
    "        # 7. source\n",
    "        source = tweet['source']\n",
    "\n",
    "        # 8. Tweet text\n",
    "        text = tweet['text']\n",
    "        \n",
    "        # Assemble all data in a list\n",
    "        res = [author_id, created_at, geo, tweet_id, lang, like_count, quote_count, reply_count, retweet_count, source, text]        \n",
    "        \n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1\n",
    "\n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Tweets added from this response: \", counter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Token:  None\n",
      "94\n",
      "{'newest_id': '1487575860672491522', 'oldest_id': '1487548323519152128', 'result_count': 94, 'next_token': 'b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "Start Date:  2022-01-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  94\n",
      "Total # of Tweets added:  94\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "97\n",
      "{'newest_id': '1487548004337086466', 'oldest_id': '1487518414650281986', 'result_count': 97, 'next_token': 'b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd\n",
      "Start Date:  2022-01-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  97\n",
      "Total # of Tweets added:  191\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "94\n",
      "{'newest_id': '1487575860672491522', 'oldest_id': '1487548323519152128', 'result_count': 94, 'next_token': 'b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "Start Date:  2022-02-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  94\n",
      "Total # of Tweets added:  285\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "97\n",
      "{'newest_id': '1487548004337086466', 'oldest_id': '1487518414650281986', 'result_count': 97, 'next_token': 'b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd\n",
      "Start Date:  2022-02-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  97\n",
      "Total # of Tweets added:  382\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "94\n",
      "{'newest_id': '1487575860672491522', 'oldest_id': '1487548323519152128', 'result_count': 94, 'next_token': 'b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "Start Date:  2022-03-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  94\n",
      "Total # of Tweets added:  476\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "97\n",
      "{'newest_id': '1487548004337086466', 'oldest_id': '1487518414650281986', 'result_count': 97, 'next_token': 'b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd\n",
      "Start Date:  2022-03-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  97\n",
      "Total # of Tweets added:  573\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "94\n",
      "{'newest_id': '1487575860672491522', 'oldest_id': '1487548323519152128', 'result_count': 94, 'next_token': 'b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "Start Date:  2022-04-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  94\n",
      "Total # of Tweets added:  667\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "97\n",
      "{'newest_id': '1487548004337086466', 'oldest_id': '1487518414650281986', 'result_count': 97, 'next_token': 'b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd\n",
      "Start Date:  2022-04-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  97\n",
      "Total # of Tweets added:  764\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "94\n",
      "{'newest_id': '1487575860672491522', 'oldest_id': '1487548323519152128', 'result_count': 94, 'next_token': 'b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "Start Date:  2022-05-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  94\n",
      "Total # of Tweets added:  858\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "97\n",
      "{'newest_id': '1487548004337086466', 'oldest_id': '1487518414650281986', 'result_count': 97, 'next_token': 'b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd\n",
      "Start Date:  2022-05-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  97\n",
      "Total # of Tweets added:  955\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "94\n",
      "{'newest_id': '1487575860672491522', 'oldest_id': '1487548323519152128', 'result_count': 94, 'next_token': 'b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "Start Date:  2022-06-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  94\n",
      "Total # of Tweets added:  1049\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "97\n",
      "{'newest_id': '1487548004337086466', 'oldest_id': '1487518414650281986', 'result_count': 97, 'next_token': 'b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd\n",
      "Start Date:  2022-06-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  97\n",
      "Total # of Tweets added:  1146\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "94\n",
      "{'newest_id': '1487575860672491522', 'oldest_id': '1487548323519152128', 'result_count': 94, 'next_token': 'b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "Start Date:  2022-07-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  94\n",
      "Total # of Tweets added:  1240\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  b26v89c19zqg8o3fpe482bydgud4dzd1iak5qs0qv8iv1\n",
      "97\n",
      "{'newest_id': '1487548004337086466', 'oldest_id': '1487518414650281986', 'result_count': 97, 'next_token': 'b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd'}\n",
      "Next Token:  b26v89c19zqg8o3fpe482bxh3kgafkgf3j3tdq8a36wsd\n",
      "Start Date:  2022-07-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  97\n",
      "Total # of Tweets added:  1337\n",
      "-------------------\n",
      "Total number of results:  1337\n"
     ]
    }
   ],
   "source": [
    "start_list = ['2022-01-01T00:00:00.000Z','2022-02-01T00:00:00.000Z','2022-03-01T00:00:00.000Z','2022-04-01T00:00:00.000Z','2022-05-01T00:00:00.000Z','2022-06-01T00:00:00.000Z','2022-07-01T00:00:00.000Z']\n",
    "end_list = ['2022-01-31T00:00:00.000Z','2021-02-28T00:00:00.000Z','2021-03-31T00:00:00.000Z','2022-04-30T00:00:00.000Z','2021-05-31T00:00:00.000Z','2021-06-30T00:00:00.000Z','2021-07-31T00:00:00.000Z']\n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "\n",
    "# Create file\n",
    "csvFile = open(\"data.csv\", \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "csvWriter.writerow(['author id', 'created_at', 'geo', 'id','lang', 'like_count', 'quote_count', 'reply_count','retweet_count','source','tweet'])\n",
    "csvFile.close()\n",
    "\n",
    "\n",
    "for i in range(0,len(start_list)):\n",
    "  # Inputs\n",
    "  count = 0 # Counting tweets per time period\n",
    "  max_count = 100 # Max tweets per time period\n",
    "  flag = True\n",
    "  next_token = None\n",
    "  # Check if flag is true\n",
    "  while flag:\n",
    "      # Check if max_count reached\n",
    "      if count >= max_count:\n",
    "        break\n",
    "      print(\"-------------------\")\n",
    "      print(\"Token: \", next_token)\n",
    "      result = get_tweets(query=query, start_time=start_time, end_time=end_time, max_results=max_count, next_token=next_token)\n",
    "      result_count = result.meta['result_count']\n",
    "      if result.meta['next_token']:\n",
    "        # Save the token to use for next call\n",
    "        next_token = result.meta['next_token']\n",
    "        print(\"Next Token: \", next_token)\n",
    "        if result_count is not None and result_count > 0 and next_token is not None:\n",
    "            print(\"Start Date: \", start_list[i])\n",
    "            append_to_csv(result, \"data.csv\")\n",
    "            count += result_count\n",
    "            total_tweets += result_count\n",
    "            print(\"Total # of Tweets added: \", total_tweets)\n",
    "            print(\"-------------------\")\n",
    "            time.sleep(5)\n",
    "      # If no next token exists\n",
    "      else:\n",
    "        if result_count is not None and result_count > 0:\n",
    "          print(\"-------------------\")\n",
    "          print(\"Start Date: \", start_list[i])\n",
    "          append_to_csv(result, \"data.csv\")\n",
    "          count += result_count\n",
    "          total_tweets += result_count\n",
    "          print(\"Total # of Tweets added: \", total_tweets)\n",
    "          print(\"-------------------\")\n",
    "          time.sleep(5)\n",
    "        \n",
    "        # Since this is the final request, turn flag to false to move to the next time period.\n",
    "        flag = False\n",
    "        next_token = None\n",
    "      time.sleep(5)\n",
    "print(\"Total number of results: \", total_tweets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d3878fddc9c46165445784a10b090b010bb1a0b9835785e50e8f56ead986c33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
